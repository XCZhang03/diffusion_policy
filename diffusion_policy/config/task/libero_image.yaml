name: libero_image

shape_meta: &shape_meta
  # acceptable types: rgb, low_dim
  obs:
    agentview_image:
      shape: [3, 128, 128]
      type: rgb
    # robot0_eye_in_hand_image:
    #   shape: [3, 128, 128]
    #   type: rgb
    robot0_eef_pos:
      shape: [3]
      # type default: low_dim
    robot0_eef_quat:
      shape: [4]
    robot0_gripper_qpos:
      shape: [2]
    lang_embed:
      shape: [768]
  action: 
    shape: [7]

benchmark_name: &benchmark_name libero_90
task_indices: &task_indices 1-40
abs_action: &abs_action False

env_runner:
  _target_: diffusion_policy.env_runner.libero_image_runner.LIBEROImageRunner
  benchmark_name: *benchmark_name
  task_indices: *task_indices
  shape_meta: *shape_meta
  # costs 1GB per env
  n_train: 10
  n_train_vis: 2
  train_start_idx: 0
  n_test: 10
  n_test_vis: 2
  test_start_seed: 100000
  # use python's eval function as resolver, single-quoted string as argument
  max_steps: ${eval:'500 if "${task.benchmark_name}" == "libero_10" else 250'}
  n_obs_steps: ${n_obs_steps}
  n_action_steps: ${n_action_steps}
  render_obs_key: 'agentview_image'
  fps: 10
  crf: 22
  past_action: ${past_action_visible}
  tqdm_interval_sec: 1.0
  n_envs: 10
# evaluation at this config requires a 16 core 64GB instance.

dataset:
  _target_: diffusion_policy.dataset.libero_image_dataset.LIBEROImageDataset
  shape_meta: *shape_meta
  benchmark_name: *benchmark_name
  task_indices: *task_indices
  horizon: ${horizon}
  pad_before: ${eval:'${n_obs_steps}-1+${n_latency_steps}'}
  pad_after: ${eval:'${n_action_steps}-1'}
  n_obs_steps: ${dataset_obs_steps}
  rotation_rep: 'rotation_6d'
  use_legacy_normalizer: False
  use_cache: True
  seed: 42
  val_ratio: 0.02
  num_demos_per_task: 30
